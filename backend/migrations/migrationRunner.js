#!/usr/bin/env node

/**
 * Supabase Migration Runner
 * –í–∏–∫–æ–Ω—É—î PostgreSQL migration scripts –≤ Supabase
 */

const fs = require('fs').promises;
const path = require('path');
const supabaseClient = require('../supabase/supabaseClient');

class MigrationRunner {
  constructor() {
    this.migrationsDir = __dirname;
    this.executedMigrations = [];
  }

  /**
   * –í–∏–∫–æ–Ω–∞—Ç–∏ –≤—Å—ñ –º—ñ–≥—Ä–∞—Ü—ñ—ó
   */
  async runMigrations() {
    console.log('üöÄ Starting Supabase Migration Runner...\n');

    try {
      // –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ Supabase
      if (!supabaseClient.isAvailable()) {
        throw new Error('Supabase client not available. Please configure .env file with Supabase credentials.');
      }

      const serviceClient = supabaseClient.getServiceClient();
      if (!serviceClient) {
        throw new Error('Supabase service client not available. Please set SUPABASE_SERVICE_ROLE_KEY in .env');
      }

      console.log('‚úÖ Supabase connection verified\n');

      // –û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ migration files
      const migrationFiles = await this.getMigrationFiles();
      console.log(`üìÅ Found ${migrationFiles.length} migration files:`);
      migrationFiles.forEach(file => console.log(`   - ${file}`));
      console.log();

      // –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ç–∞–±–ª–∏—Ü—é –¥–ª—è tracking migrations (—è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—î)
      await this.createMigrationsTable(serviceClient);

      // –û—Ç—Ä–∏–º–∞—Ç–∏ –≤–∂–µ –≤–∏–∫–æ–Ω–∞–Ω—ñ –º—ñ–≥—Ä–∞—Ü—ñ—ó
      const executedMigrations = await this.getExecutedMigrations(serviceClient);
      console.log(`üìã Already executed migrations: ${executedMigrations.length}`);

      // –í–∏–∫–æ–Ω–∞—Ç–∏ –Ω–æ–≤—ñ –º—ñ–≥—Ä–∞—Ü—ñ—ó
      let migrationCount = 0;
      for (const migrationFile of migrationFiles) {
        if (!executedMigrations.includes(migrationFile)) {
          await this.executeMigration(serviceClient, migrationFile);
          migrationCount++;
        } else {
          console.log(`‚è≠Ô∏è  Skipping ${migrationFile} (already executed)`);
        }
      }

      console.log(`\nüéØ Migration completed successfully!`);
      console.log(`üìä Executed ${migrationCount} new migrations`);
      console.log(`üìã Total migrations: ${migrationFiles.length}`);

      return true;
    } catch (error) {
      console.error('‚ùå Migration failed:', error.message);
      console.error('üîç Error details:', error);
      return false;
    }
  }

  /**
   * –û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ migration files
   */
  async getMigrationFiles() {
    try {
      const files = await fs.readdir(this.migrationsDir);
      return files
        .filter(file => file.endsWith('.sql'))
        .sort(); // –°–æ—Ä—Ç—É—î–º–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫—É –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
    } catch (error) {
      throw new Error(`Failed to read migrations directory: ${error.message}`);
    }
  }

  /**
   * –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ç–∞–±–ª–∏—Ü—é –¥–ª—è tracking migrations
   */
  async createMigrationsTable(client) {
    const createTableSQL = `
      CREATE TABLE IF NOT EXISTS schema_migrations (
        id BIGSERIAL PRIMARY KEY,
        migration_name VARCHAR(255) UNIQUE NOT NULL,
        executed_at TIMESTAMPTZ DEFAULT now(),
        execution_time_ms INTEGER,
        checksum VARCHAR(64)
      );
      
      CREATE INDEX IF NOT EXISTS idx_schema_migrations_name ON schema_migrations(migration_name);
      CREATE INDEX IF NOT EXISTS idx_schema_migrations_executed_at ON schema_migrations(executed_at);
    `;

    try {
      const { error } = await client.rpc('exec_sql', { sql: createTableSQL });
      if (error) {
        throw error;
      }
      console.log('‚úÖ Schema migrations table ready');
    } catch (error) {
      // Try alternative approach using direct SQL execution
      console.log('‚ÑπÔ∏è  Using direct table creation approach...');
      
      const { error: createError } = await client
        .from('schema_migrations')
        .select('id')
        .limit(1);
        
      if (createError && createError.code === 'PGRST116') {
        // Table doesn't exist, we'll handle this in migration file
        console.log('‚ÑπÔ∏è  Schema migrations tracking will be set up during migration');
      }
    }
  }

  /**
   * –û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –≤–∂–µ –≤–∏–∫–æ–Ω–∞–Ω–∏—Ö –º—ñ–≥—Ä–∞—Ü—ñ–π
   */
  async getExecutedMigrations(client) {
    try {
      const { data, error } = await client
        .from('schema_migrations')
        .select('migration_name')
        .order('executed_at', { ascending: true });

      if (error) {
        console.log('‚ÑπÔ∏è  No previous migrations found (table may not exist yet)');
        return [];
      }

      return data.map(row => row.migration_name);
    } catch (error) {
      console.log('‚ÑπÔ∏è  Unable to check previous migrations, starting fresh');
      return [];
    }
  }

  /**
   * –í–∏–∫–æ–Ω–∞—Ç–∏ –æ–¥–Ω—É –º—ñ–≥—Ä–∞—Ü—ñ—é
   */
  async executeMigration(client, migrationFile) {
    const startTime = Date.now();
    
    try {
      console.log(`\nüìã Executing migration: ${migrationFile}`);
      
      // –ß–∏—Ç–∞—î–º–æ SQL file
      const migrationPath = path.join(this.migrationsDir, migrationFile);
      const sqlContent = await fs.readFile(migrationPath, 'utf8');
      
      console.log(`üìÑ Migration file size: ${sqlContent.length} bytes`);

      // –†–æ–∑–¥—ñ–ª—è—î–º–æ SQL –Ω–∞ –æ–∫—Ä–µ–º—ñ statements
      const statements = this.splitSQLStatements(sqlContent);
      console.log(`üîß Executing ${statements.length} SQL statements...`);

      // –í–∏–∫–æ–Ω—É—î–º–æ –∫–æ–∂–µ–Ω statement –æ–∫—Ä–µ–º–æ
      for (let i = 0; i < statements.length; i++) {
        const statement = statements[i].trim();
        if (statement) {
          console.log(`   Statement ${i + 1}/${statements.length}...`);
          
          try {
            // Try using rpc function first
            const { error } = await client.rpc('exec_sql', { sql: statement });
            if (error) {
              throw error;
            }
          } catch (rpcError) {
            // If rpc doesn't work, we'll need to use alternative approach
            console.warn(`   ‚ö†Ô∏è  Direct SQL execution not available, migration needs manual setup`);
            throw new Error(`SQL execution not available via RPC: ${rpcError.message}`);
          }
        }
      }

      const executionTime = Date.now() - startTime;
      console.log(`‚úÖ Migration completed in ${executionTime}ms`);

      // –ó–∞–ø–∏—Å—É—î–º–æ –≤ —Ç–∞–±–ª–∏—Ü—é migrations
      await this.recordMigration(client, migrationFile, executionTime, sqlContent);

    } catch (error) {
      const executionTime = Date.now() - startTime;
      console.error(`‚ùå Migration failed after ${executionTime}ms:`, error.message);
      throw error;
    }
  }

  /**
   * –†–æ–∑–¥—ñ–ª–∏—Ç–∏ SQL –Ω–∞ –æ–∫—Ä–µ–º—ñ statements
   */
  splitSQLStatements(sql) {
    // –ü—Ä–æ—Å—Ç–∏–π —Ä–æ–∑–¥—ñ–ª –ø–æ ';' –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
    return sql
      .split('\n')
      .filter(line => !line.trim().startsWith('--') && line.trim() !== '')
      .join('\n')
      .split(';')
      .filter(statement => statement.trim() !== '');
  }

  /**
   * –ó–∞–ø–∏—Å–∞—Ç–∏ –≤–∏–∫–æ–Ω–∞–Ω—É –º—ñ–≥—Ä–∞—Ü—ñ—é
   */
  async recordMigration(client, migrationName, executionTime, sqlContent) {
    try {
      const checksum = require('crypto')
        .createHash('sha256')
        .update(sqlContent)
        .digest('hex')
        .substring(0, 16);

      const { error } = await client
        .from('schema_migrations')
        .insert({
          migration_name: migrationName,
          execution_time_ms: executionTime,
          checksum: checksum
        });

      if (error) {
        console.warn(`‚ö†Ô∏è  Could not record migration: ${error.message}`);
      } else {
        console.log(`üìù Migration recorded in schema_migrations table`);
      }
    } catch (error) {
      console.warn(`‚ö†Ô∏è  Could not record migration: ${error.message}`);
    }
  }

  /**
   * –ü–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å –º—ñ–≥—Ä–∞—Ü—ñ–π
   */
  async showMigrationStatus() {
    console.log('üìä Migration Status Check...\n');

    try {
      if (!supabaseClient.isAvailable()) {
        console.log('‚ùå Supabase not available (check .env configuration)');
        return false;
      }

      const serviceClient = supabaseClient.getServiceClient();
      const migrationFiles = await this.getMigrationFiles();
      const executedMigrations = await this.getExecutedMigrations(serviceClient);

      console.log('üìÅ Migration Files:');
      migrationFiles.forEach(file => {
        const status = executedMigrations.includes(file) ? '‚úÖ' : '‚è≥';
        console.log(`   ${status} ${file}`);
      });

      console.log(`\nüìä Summary:`);
      console.log(`   Total migrations: ${migrationFiles.length}`);
      console.log(`   Executed: ${executedMigrations.length}`);
      console.log(`   Pending: ${migrationFiles.length - executedMigrations.length}`);

      return true;
    } catch (error) {
      console.error('‚ùå Status check failed:', error.message);
      return false;
    }
  }
}

// CLI interface
if (require.main === module) {
  const command = process.argv[2] || 'migrate';
  const runner = new MigrationRunner();

  switch (command) {
    case 'migrate':
      runner.runMigrations()
        .then(success => process.exit(success ? 0 : 1))
        .catch(error => {
          console.error('üí• Unexpected error:', error);
          process.exit(1);
        });
      break;

    case 'status':
      runner.showMigrationStatus()
        .then(success => process.exit(success ? 0 : 1))
        .catch(error => {
          console.error('üí• Unexpected error:', error);
          process.exit(1);
        });
      break;

    default:
      console.log('üìã Usage:');
      console.log('   node migrationRunner.js migrate  - Run all pending migrations');
      console.log('   node migrationRunner.js status   - Show migration status');
      process.exit(1);
  }
}

module.exports = MigrationRunner; 